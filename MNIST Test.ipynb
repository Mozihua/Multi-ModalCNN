{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers, callbacks\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras import models, layers, optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "# Loading datasets\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print('Train images shape:', train_images.shape)\n",
    "print('Train labels shape:', train_labels.shape, '\\n')\n",
    "print('Test images shape:', test_images.shape)\n",
    "print('Test labels shape:', test_labels.shape, '\\n')\n",
    "\n",
    "# Showing the First MNIST handwritten number\n",
    "# plt.imshow(train_images[1], cmap='Greys')\n",
    "# plt.show()\n",
    "# print('Train image label shown:', train_labels[1], '\\n')\n",
    "\n",
    "# Training, Validation and Test datasets\n",
    "valid_images = train_images[50000:60000]\n",
    "valid_labels = train_labels[50000:60000]\n",
    "train_images = train_images[0:50000]  # test images remain untouched\n",
    "train_labels = train_labels[0:50000]\n",
    "\n",
    "# Creating Tensors\n",
    "train_images = train_images.reshape((50000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255  # converting to a [0, 1] scale\n",
    "valid_images = valid_images.reshape((10000, 28, 28, 1))\n",
    "valid_images = valid_images.astype('float32') / 255  # converting to a [0, 1] scale\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255  # converting to a [0, 1] scale\n",
    "\n",
    "# One-hot encode labels\n",
    "print('A label:', train_labels[19])\n",
    "train_labels = to_categorical(train_labels)\n",
    "valid_labels = to_categorical(valid_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print('A one-hot encode label:', train_labels[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<keras.engine.topology.InputLayer object at 0x7f08973d0890>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f08973d0f90>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f08973d0f50>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f08973ef250>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f08973ef850>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896b95cd0>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f0896b3ef50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896b4de10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896b5ed90>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896afdf90>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f0896b0ca50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896b28f50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896b3ad50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896ad5f10>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f0896ae69d0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896a84f10>, True)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896a94d10>, True)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f0896ab1f10>, True)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f0896a429d0>, True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'vgg16/block5_pool/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6eaa539a6eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Use the generated model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0moutput_vgg16_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Add the fully-connected layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2238\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    156\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    219\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    220\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3655\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   3656\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3657\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3658\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   4602\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4603\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m         data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   4605\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'vgg16/block5_pool/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,512]."
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in vgg16_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg16_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "    \n",
    "#Create your own input format (here 3x200x200)\n",
    "input = Input(shape=(28,28,3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = vgg16_conv(input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Dense(4096, activation='relu')(output_vgg16_conv)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=input, output=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()\n",
    "\n",
    "compile = my_model.compile(optimizer=optimizers.RMSprop(lr=1e-5), loss='binary_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Settting Callbacks\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3,verbose=1, cooldown=2)\n",
    "csv_logger = CSVLogger(fold+'/log.csv', append=True, separator=';')\n",
    "\n",
    "callb_l = [reduce_lr, csv_logger]\n",
    "# Train the model\n",
    "my_model.f# CNN Training\n",
    "fit = my_model.fit(x=train_images, y=train_labels, steps_per_epoch=20, epochs=50,validation_data=(valid_images, valid_labels))\n",
    "# Save Model\n",
    "my_model.save(filepath=r'media\\avell\\model_save.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture\n",
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1),\n",
    "                           use_bias=True, input_shape=(28, 28, 1)))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "my_model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), use_bias=True))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "\n",
    "my_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "my_model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "my_model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), use_bias=True))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "\n",
    "my_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "my_model.add(layers.Flatten())\n",
    "\n",
    "my_model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "my_model.add(layers.Dense(units=10, use_bias=True))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "\n",
    "my_model.add(layers.Dense(units=10, use_bias=True))\n",
    "my_model.add(layers.Activation('softmax'))\n",
    "my_model.summary()\n",
    "\n",
    "#CNN Loss and Optimizer\n",
    "compile = my_model.compile(optimizers.sgd(lr=0.3, decay=0.001), loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# CNN Training\n",
    "fit = my_model.fit(x=train_images, y=train_labels, steps_per_epoch=20, epochs=50,validation_data=(valid_images, valid_labels))\n",
    "\n",
    "# Save Model\n",
    "my_model.save(filepath=r'media\\avell\\model_save.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecturem for VGG16\n",
    "model = models.Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, 3, 3, activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, 3, 3, activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, 3, 3, activation='relu'))\n",
    "# model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, 3, 3, activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, 3, 3, activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, 3, 3, activation='relu'))\n",
    "# model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "compile = model.compile(optimizers.sgd(lr=0.3, decay=0.01), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "fit = model.fit(x=train_images, y=train_labels, batch_size=2500, epochs=100,validation_data=(valid_images, valid_labels))\n",
    "\n",
    "\n",
    "# Saving Model\n",
    "model.save(filepath=r'teste_cnn.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
