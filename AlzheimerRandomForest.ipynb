{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers, callbacks\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "%matplotlib inline\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing data to start classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    98\n",
      "0.0    98\n",
      "Name: CDR, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Generating Random Forest for data\n",
    "test_size = 0.2\n",
    "random=30\n",
    "df = pd.read_csv('Downloads/oasis_cross-sectional.csv',index_col='ID')\n",
    "#df.head()\n",
    "\n",
    "df = df[df['CDR']!=2]\n",
    "#Unmark the following line to take off in the binary classification\n",
    "#df = df[df['CDR']!=0.5]\n",
    "\n",
    "#RETURN TO GROUP 0.5 AND 1\n",
    "df['CDR'] = df['CDR'].apply(lambda x: 1 if x==0.5 else x)\n",
    "print(df['CDR'].value_counts())\n",
    "y = df['CDR'].apply(int)\n",
    "X = df.drop('Hand',axis=1) #all subjects use right hand\n",
    "\n",
    "\n",
    "#binaring gender\n",
    "X = pd.concat([X, pd.get_dummies(X['M/F'])['M']],axis=1).drop('M/F',axis=1)\n",
    "\n",
    "#converting nWBV and ASF to one-measure scale\n",
    "def conversor_1000(toBeConverted):\n",
    "    if toBeConverted < 10:\n",
    "        return toBeConverted*(10**3)\n",
    "    else:\n",
    "        return toBeConverted\n",
    "    \n",
    "X['nWBV'] = X['nWBV'].apply(conversor_1000)\n",
    "X['ASF'] = X['ASF'].apply(conversor_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vez=', 0, '\\n')\n",
      "(['Age'], ' = ', 1.5606177310065883)\n",
      "(['Educ'], ' = ', 0.5840096484598537)\n",
      "(['MMSE'], ' = ', 1.438508182110793)\n",
      "(['CDR'], ' = ', 1.5568804534541223)\n",
      "(['eTIV'], ' = ', 1.4690132665112507)\n",
      "(['nWBV'], ' = ', 1.5812759185864671)\n",
      "(['ASF'], ' = ', 1.4786001437607759)\n",
      "(['M'], ' = ', 1.5468360233695195)\n",
      "Educ\n",
      "('vez=', 1, '\\n')\n",
      "(['Educ', 'Age'], ' = ', 0.58331191874241295)\n",
      "(['Educ', 'MMSE'], ' = ', 0.58390839573466957)\n",
      "(['Educ', 'CDR'], ' = ', 0.5929668850055807)\n",
      "(['Educ', 'eTIV'], ' = ', 0.57170397811704321)\n",
      "(['Educ', 'nWBV'], ' = ', 0.58827734881585114)\n",
      "(['Educ', 'ASF'], ' = ', 0.56990011196591928)\n",
      "(['Educ', 'M'], ' = ', 0.58487032885200751)\n",
      "ASF\n",
      "('vez=', 2, '\\n')\n",
      "(['Educ', 'ASF', 'Age'], ' = ', 0.57358078491039466)\n",
      "(['Educ', 'ASF', 'MMSE'], ' = ', 0.56943543616879866)\n",
      "(['Educ', 'ASF', 'CDR'], ' = ', 0.58177411014732772)\n",
      "(['Educ', 'ASF', 'eTIV'], ' = ', 0.56831774146286118)\n",
      "(['Educ', 'ASF', 'nWBV'], ' = ', 0.57666412523673793)\n",
      "(['Educ', 'ASF', 'M'], ' = ', 0.57795509019449409)\n",
      "eTIV\n",
      "('vez=', 3, '\\n')\n",
      "(['Educ', 'ASF', 'eTIV', 'Age'], ' = ', 0.57009795298617716)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE'], ' = ', 0.56782693963393549)\n",
      "(['Educ', 'ASF', 'eTIV', 'CDR'], ' = ', 0.58010977204909953)\n",
      "(['Educ', 'ASF', 'eTIV', 'nWBV'], ' = ', 0.57468711953519425)\n",
      "(['Educ', 'ASF', 'eTIV', 'M'], ' = ', 0.57738026774396178)\n",
      "MMSE\n",
      "('vez=', 4, '\\n')\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'Age'], ' = ', 0.56856611900578669)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'CDR'], ' = ', 0.58422905104460643)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'nWBV'], ' = ', 0.57369359183979052)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'M'], ' = ', 0.57691256840603222)\n",
      "('vez=', 5, '\\n')\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'Age'], ' = ', 0.56856611900578669)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'CDR'], ' = ', 0.58422905104460643)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'nWBV'], ' = ', 0.57369359183979052)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'M'], ' = ', 0.57691256840603222)\n",
      "('vez=', 6, '\\n')\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'Age'], ' = ', 0.56856611900578669)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'CDR'], ' = ', 0.58422905104460643)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'nWBV'], ' = ', 0.57369359183979052)\n",
      "(['Educ', 'ASF', 'eTIV', 'MMSE', 'M'], ' = ', 0.57691256840603222)\n"
     ]
    }
   ],
   "source": [
    "def progressive_sampling(xLabel,yLabel):\n",
    "    lre = LinearRegression()\n",
    "    best_combination = []\n",
    "    r2 = 10000\n",
    "    valid = []\n",
    "\n",
    "\n",
    "    for a in xLabel:\n",
    "        valid.append(a)\n",
    "    \n",
    "    for i in range(len(xLabel)-1):\n",
    "        print('vez=',i,'\\n')\n",
    "        entrou = False\n",
    "        for j in valid:                              \n",
    "            best_combination.append(j)\n",
    "            #print(xr_train[best_combination].head())\n",
    "            #print(yr_train.head())\n",
    "            lre.fit(xr_train[best_combination],yr_train)\n",
    "            pre = lre.predict(xr_test[best_combination])\n",
    "            print(best_combination,' = ',mean_squared_error(yr_test,pre))\n",
    "            best_combination.remove(j)\n",
    "            if mean_squared_error(yr_test,pre) < r2:\n",
    "                r2 = mean_squared_error(yr_test,pre)\n",
    "                value = j\n",
    "                entrou=True\n",
    "        if entrou:        \n",
    "            best_combination.append(value)\n",
    "            print(value)\n",
    "            valid.remove(value)\n",
    "\n",
    "    return best_combination\n",
    "\n",
    "yLabel = 'SES'\n",
    "Xra = X[~X['SES'].isnull()]    \n",
    "xr_train, xr_test, yr_train, yr_test = train_test_split(Xra.drop(yLabel,axis=1),Xra[yLabel], test_size=test_size,random_state=random)\n",
    "\n",
    "teste=np.array(X.drop('SES',axis=1).columns).ravel()\n",
    "best_predictors = progressive_sampling(teste,'SES')            \n",
    "#sns.pairplot(X[~X['SES'].isnull()],hue='CDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Age  Educ       SES  MMSE  CDR  eTIV   nWBV     ASF  M\n",
      "ID                                                                   \n",
      "OAS1_0072_MR1   60     5  1.000000    30  0.0  1402  823.0  1252.0  0\n",
      "OAS1_0200_MR1   60     2  4.000000    30  0.0  1366  807.0  1285.0  0\n",
      "OAS1_0109_MR1   61     4  3.000000    30  0.0  1313  813.0  1337.0  0\n",
      "OAS1_0455_MR1   61     2  4.000000    28  0.0  1354  825.0  1297.0  0\n",
      "OAS1_0456_MR1   61     5  2.000000    30  0.0  1637  780.0  1072.0  1\n",
      "OAS1_0114_MR1   62     2  4.000000    30  0.0  1378  804.0  1274.0  1\n",
      "OAS1_0457_MR1   62     3  3.000000    26  0.0  1372  766.0  1279.0  0\n",
      "OAS1_0070_MR1   63     3  2.000000    30  0.0  1327  801.0  1323.0  0\n",
      "OAS1_0078_MR1   64     3  2.000000    30  0.0  1395  809.0  1258.0  0\n",
      "OAS1_0135_MR1   64     2  4.000000    29  0.0  1561  801.0  1124.0  1\n",
      "OAS1_0292_MR1   64     4  2.000000    30  0.0  1415  766.0  1240.0  0\n",
      "OAS1_0030_MR1   65     2  3.000000    29  0.0  1392  764.0  1261.0  0\n",
      "OAS1_0133_MR1   65     5  2.000000    30  0.0  1277  814.0  1374.0  0\n",
      "OAS1_0322_MR1   65     3  4.000000    29  0.0  1335  776.0  1315.0  0\n",
      "OAS1_0358_MR1   65     3  3.000000    29  0.0  1362  839.0  1289.0  1\n",
      "OAS1_0438_MR1   66     5  2.000000    29  0.0  1191  787.0  1474.0  0\n",
      "OAS1_0068_MR1   67     3  4.000000    30  0.0  1508  805.0  1164.0  0\n",
      "OAS1_0303_MR1   67     2  4.000000    30  0.0  1221  831.0  1438.0  0\n",
      "OAS1_0130_MR1   68     3  3.000000    26  0.0  1444  789.0  1216.0  1\n",
      "OAS1_0343_MR1   68     3  3.000000    30  0.0  1441  811.0  1217.0  1\n",
      "OAS1_0356_MR1   68     3  2.000000    30  0.0  1506  740.0  1165.0  0\n",
      "OAS1_0112_MR1   69     5  2.000000    29  0.0  1536  733.0  1143.0  0\n",
      "OAS1_0199_MR1   69     5  1.000000    30  0.0  1601  784.0  1096.0  1\n",
      "OAS1_0293_MR1   69     1  2.000000    26  0.0  1384  783.0  1268.0  0\n",
      "OAS1_0422_MR1   69     4  3.000000    29  0.0  1380  809.0  1272.0  0\n",
      "OAS1_0085_MR1   70     2  3.000000    29  0.0  1283  791.0  1368.0  0\n",
      "OAS1_0256_MR1   70     5  1.000000    30  0.0  1660  739.0  1057.0  1\n",
      "OAS1_0371_MR1   70     3  4.000000    30  0.0  1361  783.0  1290.0  0\n",
      "OAS1_0170_MR1   71     2  4.000000    29  0.0  1455  725.0  1206.0  1\n",
      "OAS1_0203_MR1   71     2  3.000000    30  0.0  1360  779.0  1291.0  0\n",
      "...            ...   ...       ...   ...  ...   ...    ...     ... ..\n",
      "OAS1_0287_MR1   78     3  3.000000    21  1.0  1194  694.0  1470.0  0\n",
      "OAS1_0060_MR1   79     4  1.964451    29  1.0  1564  734.0  1122.0  1\n",
      "OAS1_0263_MR1   79     4  1.000000    30  1.0  1722  709.0  1019.0  1\n",
      "OAS1_0339_MR1   79     2  3.548960    24  1.0  1211  694.0  1449.0  0\n",
      "OAS1_0021_MR1   80     3  3.000000    23  1.0  1794  765.0   978.0  0\n",
      "OAS1_0042_MR1   80     4  2.000000    29  1.0  1854  709.0   947.0  1\n",
      "OAS1_0166_MR1   80     2  3.244090    27  1.0  1475  771.0  1190.0  0\n",
      "OAS1_0267_MR1   80     5  2.000000    28  1.0  1506  679.0  1166.0  1\n",
      "OAS1_0329_MR1   80     2  3.000000    29  1.0  1209  760.0  1451.0  0\n",
      "OAS1_0335_MR1   80     1  4.000000    27  1.0  1654  678.0  1061.0  0\n",
      "OAS1_0084_MR1   81     2  3.260129    27  1.0  1453  727.0  1208.0  0\n",
      "OAS1_0158_MR1   81     5  1.000000    26  1.0  1556  689.0  1128.0  1\n",
      "OAS1_0164_MR1   81     2  3.000000    28  1.0  1495  687.0  1174.0  0\n",
      "OAS1_0352_MR1   81     5  2.000000    26  1.0  1174  743.0  1495.0  0\n",
      "OAS1_0441_MR1   81     5  1.000000    29  1.0  1647  721.0  1066.0  1\n",
      "OAS1_0016_MR1   82     2  4.000000    27  1.0  1477  739.0  1188.0  1\n",
      "OAS1_0023_MR1   82     2  3.000000    27  1.0  1420  710.0  1236.0  1\n",
      "OAS1_0123_MR1   83     3  4.000000    24  1.0  1282  797.0  1369.0  0\n",
      "OAS1_0286_MR1   83     3  2.000000    20  1.0  1476  751.0  1189.0  0\n",
      "OAS1_0290_MR1   83     3  2.000000    26  1.0  1992  706.0   881.0  1\n",
      "OAS1_0380_MR1   83     1  5.000000    18  1.0  1313  705.0  1337.0  0\n",
      "OAS1_0161_MR1   84     2  2.000000    27  1.0  1390  727.0  1263.0  0\n",
      "OAS1_0304_MR1   84     3  3.000000    29  1.0  1497  693.0  1172.0  1\n",
      "OAS1_0440_MR1   86     1  4.000000    27  1.0  1320  723.0  1329.0  1\n",
      "OAS1_0179_MR1   87     2  4.000000    21  1.0  1250  653.0  1405.0  0\n",
      "OAS1_0273_MR1   89     1  4.000000    18  1.0  1480  676.0  1186.0  0\n",
      "OAS1_0226_MR1   90     1  4.000000    23  1.0  1668  644.0  1052.0  1\n",
      "OAS1_0247_MR1   90     2  3.000000    21  1.0  1307  689.0  1342.0  1\n",
      "OAS1_0400_MR1   92     5  1.000000    25  1.0  1774  644.0   989.0  0\n",
      "OAS1_0447_MR1   92     4  1.000000    24  1.0  1388  739.0  1264.0  0\n",
      "\n",
      "[196 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#setting missing data from SES using linear regression\n",
    "\n",
    "#RETURN BECAUSE ITS WORKING\n",
    "lr = LinearRegression()\n",
    "lr.fit(Xra[best_predictors],Xra[yLabel])\n",
    "predicted_r = lr.predict(X[X['SES'].isnull()][best_predictors])\n",
    "updatex = pd.Series(predicted_r,index=X[X['SES'].isnull()].index)\n",
    "X['SES'].update(updatex)\n",
    "print(X)\n",
    "\n",
    "\n",
    "\n",
    "#LEFT THIS WAY\n",
    "\n",
    "#X[X['SES'].isnull()]['SES'] = update\n",
    "\n",
    "#print(X)\n",
    "#def insert_SES():\n",
    "    \n",
    "#predicted_r\n",
    "\n",
    "\n",
    "\n",
    "##Testes\n",
    "##X[X['SES'].isnull()]\n",
    "##np.hstack((predicted_r.reshape((len(predicted_r),1)),yr_test.reshape((len(predicted_r),1))))\n",
    "\n",
    "##print(mean_squared_error(yr_test,predicted_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using z-score\n",
    "ss = StandardScaler()\n",
    "scaled = ss.fit_transform(X.drop(['CDR'],axis=1))\n",
    "X_zscore = pd.DataFrame(scaled,columns=X.drop(['CDR'],axis=1).columns)\n",
    "#print(X_zscore.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_zscore, y.apply(str), test_size=test_size, random_state=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_subset(x,y,k=10):\n",
    "    from random import Random\n",
    "    from itertools import cycle\n",
    "    temp_s = list(zip(x,y))\n",
    "    Random(42).shuffle(temp_s)\n",
    "    x,y = zip(*temp_s)\n",
    "    \n",
    "    TEST = int(len(y)*0.1)\n",
    "    TRAIN = len(y)-TEST\n",
    "    \n",
    "    rtn_x,rtn_y = np.zeros(k,dtype=tuple), np.zeros(k,dtype=tuple)\n",
    "    \n",
    "    for i in range(k):\n",
    "        start = i*TEST\n",
    "        np.roll(x,start); np.roll(y,start)\n",
    "        rtn_x[i] = (x[0:TRAIN],x[TRAIN:])\n",
    "        rtn_y[i] = (y[0:TRAIN],y[TRAIN:])\n",
    "    return rtn_x, rtn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "        1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def super_learner(x,y,x_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    rf = RandomForestClassifier(bootstrap=True, class_weight=None,n_estimators=500, criterion='gini')\n",
    "    nb = GaussianNB()\n",
    "    svm = SVC()\n",
    "    \n",
    "    k_x,k_y = cross_val_subset(x,y)\n",
    "    \n",
    "    level_one_l = []\n",
    "    SL_rf, SL_nb, SL_svm = [],[],[]\n",
    "    classifiers = [rf,nb,svm]\n",
    "    features = [SL_rf, SL_nb,SL_svm]\n",
    "    y_labels = [] \n",
    "    \n",
    "    for fold_x, fold_y in zip(k_x,k_y):\n",
    "        [i.fit(fold_x[0],fold_y[0]) for i in classifiers]\n",
    "        [f.append(c.predict(fold_x[1])) for c,f in zip(classifiers,features)]\n",
    "        y_labels.append(fold_y[1])\n",
    "    [level_one_l.append(np.array(f).ravel()) for f in features]\n",
    "    f_len = len(level_one_l[0])\n",
    "    level_one = np.hstack([np.reshape(l,(f_len,1)) for l in level_one_l])\n",
    "    level_one = np.hstack([level_one,np.reshape(np.array(y_labels),(f_len,1))]).astype(float)\n",
    "    \n",
    "    test_f = [c.predict(x_test) for c in classifiers]\n",
    "    t_len = len(test_f[0])\n",
    "    level_two = np.hstack([np.reshape(t,(t_len,1)) for t in test_f]).astype(float)\n",
    "    \n",
    "    l2 = SVC()\n",
    "    l2.fit(level_one[:,:3],level_one[:,3])\n",
    "    \n",
    "    prediction = l2.predict(level_two)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "sl_f = super_learner(X_train.values, y_train.values,X_test.values)\n",
    "sl_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.82      0.82        17\n",
      "        1.0       0.87      0.87      0.87        23\n",
      "\n",
      "avg / total       0.85      0.85      0.85        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sl_f,y_test.values.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.75      0.81        20\n",
      "          1       0.78      0.90      0.84        20\n",
      "\n",
      "avg / total       0.83      0.82      0.82        40\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.76      0.84        21\n",
      "          1       0.78      0.95      0.86        19\n",
      "\n",
      "avg / total       0.87      0.85      0.85        40\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.73      0.82        22\n",
      "          1       0.74      0.94      0.83        18\n",
      "\n",
      "avg / total       0.85      0.82      0.82        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None,n_estimators=500, criterion='gini')\n",
    "nb = GaussianNB()\n",
    "svm = SVC()\n",
    "\n",
    "rf.fit(X_train.values,y_train.values)\n",
    "nb.fit(X_train.values,y_train.values)\n",
    "svm.fit(X_train.values,y_train.values)\n",
    "\n",
    "pr = rf.predict(X_test)\n",
    "pn = nb.predict(X_test)\n",
    "ps = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(pr,y_test.values))\n",
    "print(classification_report(pn,y_test.values))\n",
    "print(classification_report(ps,y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.corr of      0\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    1\n",
      "5    0\n",
      "6    1\n",
      "7    1\n",
      "8    0\n",
      "9    0\n",
      "10   0\n",
      "11   1\n",
      "12   0\n",
      "13   0\n",
      "14   1\n",
      "15   0\n",
      "16   1\n",
      "17   0\n",
      "18   1\n",
      "19   1\n",
      "20   0\n",
      "21   0\n",
      "22   1\n",
      "23   0\n",
      "24   0\n",
      "25   1\n",
      "26   1\n",
      "27   0\n",
      "28   0\n",
      "29   1\n",
      "..  ..\n",
      "90   0\n",
      "91   1\n",
      "92   0\n",
      "93   0\n",
      "94   1\n",
      "95   0\n",
      "96   1\n",
      "97   0\n",
      "98   1\n",
      "99   1\n",
      "100  0\n",
      "101  0\n",
      "102  1\n",
      "103  1\n",
      "104  0\n",
      "105  0\n",
      "106  1\n",
      "107  0\n",
      "108  0\n",
      "109  1\n",
      "110  1\n",
      "111  0\n",
      "112  0\n",
      "113  1\n",
      "114  0\n",
      "115  0\n",
      "116  0\n",
      "117  0\n",
      "118  0\n",
      "119  1\n",
      "\n",
      "[120 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.vstack([np.reshape(pr,(len(pr),1)),np.reshape(pn,(len(pr),1)),np.reshape(ps,(len(pr),1))]))\n",
    "print(df.corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
