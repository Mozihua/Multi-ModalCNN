{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train images shape:', (60000, 28, 28))\n",
      "('Train labels shape:', (60000,), '\\n')\n",
      "('Test images shape:', (10000, 28, 28))\n",
      "('Test labels shape:', (10000,), '\\n')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers, optimizers\n",
    "from os import environ\n",
    "\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Loading datasets\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print('Train images shape:', train_images.shape)\n",
    "print('Train labels shape:', train_labels.shape, '\\n')\n",
    "print('Test images shape:', test_images.shape)\n",
    "print('Test labels shape:', test_labels.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 11s 1us/step\n",
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,) \n",
      "\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,) \n",
      "\n",
      "A label: 9\n",
      "A one-hot encode label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                4010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,920\n",
      "Trainable params: 8,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 2.1633 - acc: 0.1972 - val_loss: 2.2049 - val_acc: 0.2544\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 1.6733 - acc: 0.4674 - val_loss: 1.0255 - val_acc: 0.6651\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.7653 - acc: 0.7522 - val_loss: 0.3807 - val_acc: 0.9014\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.5221 - acc: 0.8386 - val_loss: 0.2707 - val_acc: 0.9242\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.3779 - acc: 0.8839 - val_loss: 0.2315 - val_acc: 0.9344\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.3363 - acc: 0.8963 - val_loss: 0.2004 - val_acc: 0.9445\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.3079 - acc: 0.9059 - val_loss: 0.1821 - val_acc: 0.9487\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.2833 - acc: 0.9122 - val_loss: 0.1727 - val_acc: 0.9510\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.2691 - acc: 0.9187 - val_loss: 0.1623 - val_acc: 0.9537\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.2536 - acc: 0.9221 - val_loss: 0.1540 - val_acc: 0.9557\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.2417 - acc: 0.9261 - val_loss: 0.1454 - val_acc: 0.9599\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.2353 - acc: 0.9285 - val_loss: 0.1409 - val_acc: 0.9597\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.2310 - acc: 0.9294 - val_loss: 0.1361 - val_acc: 0.9611\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.2223 - acc: 0.9319 - val_loss: 0.1329 - val_acc: 0.9632\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.2124 - acc: 0.9346 - val_loss: 0.1281 - val_acc: 0.9633\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.2061 - acc: 0.9369 - val_loss: 0.1254 - val_acc: 0.9637\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.2034 - acc: 0.9387 - val_loss: 0.1218 - val_acc: 0.9653\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.1990 - acc: 0.9394 - val_loss: 0.1200 - val_acc: 0.9658\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.1964 - acc: 0.9398 - val_loss: 0.1171 - val_acc: 0.9660\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.1926 - acc: 0.9414 - val_loss: 0.1150 - val_acc: 0.9670\n"
     ]
    }
   ],
   "source": [
    "# Showing the First MNIST handwritten number\n",
    "# plt.imshow(train_images[1], cmap='Greys')\n",
    "# plt.show()\n",
    "# print('Train image label shown:', train_labels[1], '\\n')\n",
    "\n",
    "# Training, Validation and Test datasets\n",
    "valid_images = train_images[50000:60000]\n",
    "valid_labels = train_labels[50000:60000]\n",
    "train_images = train_images[0:50000]  # test images remain untouched\n",
    "train_labels = train_labels[0:50000]\n",
    "\n",
    "# Creating Tensors\n",
    "train_images = train_images.reshape((50000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255  # converting to a [0, 1] scale\n",
    "valid_images = valid_images.reshape((10000, 28, 28, 1))\n",
    "valid_images = valid_images.astype('float32') / 255  # converting to a [0, 1] scale\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255  # converting to a [0, 1] scale\n",
    "\n",
    "# One-hot encode labels\n",
    "print('A label:', train_labels[19])\n",
    "train_labels = to_categorical(train_labels)\n",
    "valid_labels = to_categorical(valid_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print('A one-hot encode label:', train_labels[19])\n",
    "\n",
    "# CNN Architecture\n",
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1),\n",
    "                           use_bias=True, input_shape=(28, 28, 1)))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "my_model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), use_bias=True))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "\n",
    "my_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "my_model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "my_model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), use_bias=True))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "\n",
    "my_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "my_model.add(layers.Flatten())\n",
    "\n",
    "my_model.add(layers.Dropout(rate=0.2))\n",
    "\n",
    "my_model.add(layers.Dense(units=10, use_bias=True))\n",
    "my_model.add(layers.Activation('relu'))\n",
    "\n",
    "my_model.add(layers.Dense(units=10, use_bias=True))\n",
    "my_model.add(layers.Activation('softmax'))\n",
    "\n",
    "# CNN Summary\n",
    "my_model.summary()\n",
    "\n",
    "# CNN Loss and Optimizer\n",
    "compile = my_model.compile(optimizers.sgd(lr=0.3, decay=0.01), loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# CNN Training\n",
    "fit = my_model.fit(x=train_images, y=train_labels, batch_size=2500, epochs=20,\n",
    "                   validation_data=(valid_images, valid_labels))\n",
    "\n",
    "# Save Model\n",
    "my_model.save(filepath=r'model_save.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                4010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,920\n",
      "Trainable params: 8,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "Last node Biases:\n",
      "[-0.05509712  0.41314006 -0.01392789 -0.19427258 -0.3031597  -0.00241213\n",
      " -0.1336538   0.14997898  0.14079419 -0.00138944]\n",
      "Last node Weights:\n",
      "[[-0.52990085  0.24460854  0.5068315   0.05495615  0.24895525  0.17926732\n",
      "   0.3892653  -0.11045009 -0.24249147 -0.26172882]\n",
      " [ 0.24822833  0.7209381   0.43453646  0.53850627 -0.14550024 -0.41224447\n",
      "  -0.44770575  0.1813141   0.03379582  0.00524132]\n",
      " [-0.26468557 -0.1284481  -0.16241372 -0.13667268  0.6805228  -0.47552013\n",
      "  -0.00905392 -0.03092571  0.56530833  0.15587589]\n",
      " [-0.29269624 -0.25285447 -0.49765027  0.46828362 -0.23921283  0.71853286\n",
      "  -0.45064905 -0.30138102  0.17897178  0.26034915]\n",
      " [ 0.22350363 -0.5139161   0.64216113 -0.22792928 -0.35457182  0.02362015\n",
      "   0.14315963 -0.05860604  0.41063124 -0.15114601]\n",
      " [-0.32277045 -0.16870415 -0.07807529 -0.46786037  0.34852234 -0.4804114\n",
      "  -0.6772839   0.24356802 -0.36743644  0.5805109 ]\n",
      " [-0.3843231   0.60173064 -0.0089227  -0.07262325  0.28708854  0.1416347\n",
      "   0.6868502  -0.39006853 -0.13693714 -0.61069304]\n",
      " [-0.11651367 -0.27698278 -0.33427942 -0.18603882  0.18416739 -0.1104687\n",
      "   0.33561122  0.8718667  -0.07244268 -0.12119436]\n",
      " [-0.5085246  -0.07601336  0.23813157  0.2471426  -0.20277424  0.33237165\n",
      "   0.324337    0.63193387  0.10630848 -0.38543653]\n",
      " [ 0.8325194  -0.59684163 -0.3897974   0.10136711  0.03110343  0.26048934\n",
      "   0.46847102  0.29195872 -0.236494    0.22283632]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Number Image Prediction is: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "Evaluation Accuracy is: 96.55%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from numpy import random\n",
    "\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Loading Model\n",
    "my_model = load_model(filepath=r'model_save.h5')\n",
    "print(my_model.summary(), '\\n')\n",
    "\n",
    "# Showing Parameters: Weights and Biases\n",
    "print('Last node Biases:')\n",
    "print(my_model.get_weights()[-1])\n",
    "print('Last node Weights:')\n",
    "print(my_model.get_weights()[-2])\n",
    "\n",
    "# Loading MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "rand_n = random.randint(0, 10000)\n",
    "rand_i = test_images[rand_n]\n",
    "plt.imshow(rand_i, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "# Predicting a Random Number Image\n",
    "pred = my_model.predict(rand_i.reshape(1, 28, 28, 1), batch_size=1)\n",
    "print('The Random Number Image Prediction is: {}'.format(pred))\n",
    "\n",
    "# Evaluation test over Test dataset\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_labels = to_categorical(test_labels)\n",
    "(eval_l, eval_acc) = my_model.evaluate(test_images, y=test_labels, batch_size=10000)\n",
    "print('Evaluation Accuracy is: {:4.2f}%'.format(eval_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
