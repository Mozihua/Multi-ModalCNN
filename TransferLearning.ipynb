{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers, callbacks\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "val_idg = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "test_idg = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<keras.engine.topology.InputLayer object at 0x7fba9f86af90>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9f8d3ad0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fbb24fdcd90>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fba9f87c150>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9f8d3910>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9f89fad0>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fba9f047f10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9f05af10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9efe9c50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9f008e90>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9f01a8d0>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fba9efb7790>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9efd4ad0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9ef61a10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9ef7e8d0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9ef8e690>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fba9ef2d550>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9ef4a890>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9ef5a7d0>, True)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9eef86d0>, True)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fba9ef0a490>, True)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fba9eea7390>, True)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "vgg19_conv = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in vgg19_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg19_conv.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create your own input format (here 3x200x200)\n",
    "input = Input(shape=(91,109,3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = vgg16_conv(input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=input, output=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/ipykernel_launcher.py:63: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., verbose=1, validation_data=<keras.pre..., steps_per_epoch=257, epochs=50, callbacks=[<keras.ca..., validation_steps=466)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "257/257 [==============================] - 42s 162ms/step - loss: 0.7038 - acc: 0.5214 - val_loss: 0.6931 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51574, saving model to /media/avell/Novo volume/GM_CORONAL/fold_0/vgg19_1.h5\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.6666 - acc: 0.5795 - val_loss: 0.6805 - val_acc: 0.5508\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.51574 to 0.55079, saving model to /media/avell/Novo volume/GM_CORONAL/fold_0/vgg19_1.h5\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 42s 162ms/step - loss: 0.6150 - acc: 0.6620 - val_loss: 0.7076 - val_acc: 0.5439\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 41s 160ms/step - loss: 0.5630 - acc: 0.7050 - val_loss: 0.7394 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55079 to 0.64354, saving model to /media/avell/Novo volume/GM_CORONAL/fold_0/vgg19_1.h5\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 41s 160ms/step - loss: 0.5064 - acc: 0.7485 - val_loss: 0.8905 - val_acc: 0.4819\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.4376 - acc: 0.8013 - val_loss: 1.0646 - val_acc: 0.5167\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.3669 - acc: 0.8448 - val_loss: 1.0864 - val_acc: 0.5308\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 41s 160ms/step - loss: 0.3071 - acc: 0.8694 - val_loss: 1.3266 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.2318 - acc: 0.9105 - val_loss: 1.4198 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 41s 160ms/step - loss: 0.1196 - acc: 0.9577 - val_loss: 1.7103 - val_acc: 0.5536\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 41s 161ms/step - loss: 0.1282 - acc: 0.9506 - val_loss: 1.7699 - val_acc: 0.5489\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 42s 162ms/step - loss: 0.0778 - acc: 0.9718 - val_loss: 2.6769 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 40s 157ms/step - loss: 0.0273 - acc: 0.9927 - val_loss: 2.8376 - val_acc: 0.5429\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.0189 - acc: 0.9949 - val_loss: 2.8711 - val_acc: 0.5660\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 00014: early stopping\n",
      "Found 152 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 42s 163ms/step - loss: 0.7051 - acc: 0.5085 - val_loss: 0.6984 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49332, saving model to /media/avell/Novo volume/GM_CORONAL/fold_1/vgg19_1.h5\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.6638 - acc: 0.5924 - val_loss: 0.6382 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.49332 to 0.62828, saving model to /media/avell/Novo volume/GM_CORONAL/fold_1/vgg19_1.h5\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 40s 157ms/step - loss: 0.6227 - acc: 0.6518 - val_loss: 0.6255 - val_acc: 0.5873\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.5773 - acc: 0.6877 - val_loss: 0.7648 - val_acc: 0.4914\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.5290 - acc: 0.7349 - val_loss: 1.1425 - val_acc: 0.4235\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 41s 161ms/step - loss: 0.5142 - acc: 0.7476 - val_loss: 0.6667 - val_acc: 0.6376\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.62828 to 0.63758, saving model to /media/avell/Novo volume/GM_CORONAL/fold_1/vgg19_1.h5\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 41s 161ms/step - loss: 0.4320 - acc: 0.7982 - val_loss: 0.8265 - val_acc: 0.5629\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 41s 160ms/step - loss: 0.3757 - acc: 0.8307 - val_loss: 0.6369 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.63758 to 0.73414, saving model to /media/avell/Novo volume/GM_CORONAL/fold_1/vgg19_1.h5\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.2798 - acc: 0.8845 - val_loss: 1.3207 - val_acc: 0.2802\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.2914 - acc: 0.8767 - val_loss: 0.7735 - val_acc: 0.5205\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.1565 - acc: 0.9419 - val_loss: 1.5496 - val_acc: 0.5250\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 41s 161ms/step - loss: 0.1424 - acc: 0.9472 - val_loss: 2.1016 - val_acc: 0.4356\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.0770 - acc: 0.9708 - val_loss: 1.7731 - val_acc: 0.6245\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.0545 - acc: 0.9786 - val_loss: 1.5367 - val_acc: 0.6676\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 41s 159ms/step - loss: 0.0603 - acc: 0.9769 - val_loss: 1.4427 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.0310 - acc: 0.9895 - val_loss: 3.0239 - val_acc: 0.3782\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 40s 158ms/step - loss: 0.0345 - acc: 0.9898 - val_loss: 2.7328 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 40s 157ms/step - loss: 0.0033 - acc: 0.9998 - val_loss: 2.6079 - val_acc: 0.5370\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 00018: early stopping\n",
      "Found 152 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 42s 162ms/step - loss: 0.7036 - acc: 0.5090 - val_loss: 0.6730 - val_acc: 0.5832\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58321, saving model to /media/avell/Novo volume/GM_CORONAL/fold_2/vgg19_1.h5\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 40s 157ms/step - loss: 0.6740 - acc: 0.5747 - val_loss: 0.6434 - val_acc: 0.5794\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 41s 158ms/step - loss: 0.6176 - acc: 0.6542 - val_loss: 0.6963 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.58321 to 0.59371, saving model to /media/avell/Novo volume/GM_CORONAL/fold_2/vgg19_1.h5\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 40s 157ms/step - loss: 0.5744 - acc: 0.6965 - val_loss: 0.7991 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.59371 to 0.62160, saving model to /media/avell/Novo volume/GM_CORONAL/fold_2/vgg19_1.h5\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 40s 157ms/step - loss: 0.5024 - acc: 0.7524 - val_loss: 0.9116 - val_acc: 0.5353\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/50\n",
      "185/257 [====================>.........] - ETA: 4s - loss: 0.4272 - acc: 0.7963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c521908bf09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m           callbacks=callb_l)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Then training with your data ! \n",
    "# Compile the model\n",
    "# Model Loss function and Optimizer method\n",
    "from keras.callbacks import CSVLogger,ModelCheckpoint, EarlyStopping\n",
    "\n",
    "DEST = '/media/avell/Novo volume/GM_CORONAL/'\n",
    "img_width, img_height = 91, 91\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    fold = DEST+'fold_{}'.format(i)\n",
    "    train_g = train_idg.flow_from_directory(\n",
    "        fold+'/train',\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size= 16,\n",
    "        class_mode='binary')\n",
    "    val_g   = val_idg.flow_from_directory(\n",
    "        fold+'/validation',\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size= 16,\n",
    "        class_mode='binary')\n",
    "\n",
    "    #Get back the convolutional part of a VGG network trained on ImageNet\n",
    "    model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width,img_height,3))\n",
    "\n",
    "    # Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "    for layer in model.layers[:5]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "    x = model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model_final = Model(input = model.input, output = predictions)\n",
    "    \n",
    "    # compile the model \n",
    "    model_final.compile(optimizer = optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                                     loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    # Settting Callbacks\n",
    "    checkpoint = ModelCheckpoint(fold+\"/vgg19_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    csv_logger = CSVLogger(fold+'/log.csv', append=True, separator=';')\n",
    "\n",
    "    callb_l = [checkpoint,csv_logger,early]\n",
    "    # Train the model\n",
    "    model_final.fit_generator(\n",
    "          train_g,\n",
    "          samples_per_epoch = nb_train_samples,\n",
    "          epochs = epochs,\n",
    "          nb_val_samples = nb_validation_samples,\n",
    "          validation_data=val_g,\n",
    "          verbose=1,\n",
    "          callbacks=callb_l)\n",
    "\n",
    "    # Save the model\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 2 classes.\n",
      "\n",
      "Evaluation accuracy: 0.70\n",
      "Found 18 images belonging to 2 classes.\n",
      "\n",
      "Evaluation accuracy: 0.40\n",
      "Found 18 images belonging to 2 classes.\n",
      "\n",
      "Evaluation accuracy: 0.60\n",
      "Found 17 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to open file (unable to open file: name = '/media/avell/Novo volume/GM_CORONAL/fold_3/vgg19_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a56a14638af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         class_mode='binary')\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/vgg19_1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;31m# instantiate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avell/anaconda3/envs/p3env/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (unable to open file: name = '/media/avell/Novo volume/GM_CORONAL/fold_3/vgg19_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import csv\n",
    "\n",
    "DEST = '/media/avell/Novo volume/GM_CORONAL/'\n",
    "\n",
    "for i in range(10):\n",
    "    K.clear_session()\n",
    "    \n",
    "    fold = DEST+'fold_{}'.format(i)\n",
    "    test_g = test_idg.flow_from_directory(\n",
    "        fold+'/test',\n",
    "        target_size=(91,91),\n",
    "        batch_size= 10,\n",
    "        class_mode='binary')\n",
    "\n",
    "    my_model = load_model(filepath=fold+'/vgg19_1.h5')\n",
    "\n",
    "    (eval_loss, eval_acc) = my_model.evaluate_generator(generator=test_g,steps=1)\n",
    "    print('\\nEvaluation accuracy: {:.2f}'.format(eval_acc))\n",
    "\n",
    "    pred = my_model.predict_generator(test_g)\n",
    "\n",
    "    pred[pred >= 0.5] = 1\n",
    "    pred[pred != 1 ] = 0\n",
    "    \n",
    "    pr,rl,f1,sp = precision_recall_fscore_support(pred, test_g.classes)\n",
    "    acc = accuracy_score(pred, test_g.classes)\n",
    "    tn, fp, fn, tp = confusion_matrix(pred, test_g.classes).ravel()\n",
    "    specificity = 1.0*tn / (tn+fp)\n",
    "    \n",
    "    with open(fold+'/fold_{}_metrics.csv'.format(i),'wb') as csvFile:\n",
    "        filewriter = csv.writer(csvFile)\n",
    "        filewriter.writerow(['class','precision','recall','fscore','support','accuracy','specificity'])\n",
    "        filewriter.writerow([0,pr[0],rl[0],f1[0],sp[0],'-','-'])\n",
    "        filewriter.writerow([1,pr[1],rl[1],f1[1],sp[1],'-','-'])\n",
    "        filewriter.writerow(['-','-','-','-','-',acc,specificity])\n",
    "    csvFile.close()\n",
    "    \n",
    "    np.save(fold+'/fold_{}_pred_labels.npy'.format(i),pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SuperLearner features creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST = '/media/avell/Novo volume/OASIS_CV_axial/'\n",
    "EXT = '_a.jpg'\n",
    "FIG_SHAPE = (208,176)\n",
    "\n",
    "for i in range(10):\n",
    "    ldst = DEST+'fold_{}/train/'.format(i)\n",
    "    k_labels = []\n",
    "    for j in range(10):\n",
    "        fold = ldst+'fold_{}'.format(j)\n",
    "        train_g = train_idg.flow_from_directory(\n",
    "            fold+'/train',\n",
    "            target_size=FIG_SHAPE,\n",
    "            batch_size= 10,\n",
    "            class_mode='binary')\n",
    "        val_g   = val_idg.flow_from_directory(\n",
    "            fold+'/validation',\n",
    "            target_size=FIG_SHAPE,\n",
    "            batch_size= 10,\n",
    "            class_mode='binary')\n",
    "        test_g = test_idg.flow_from_directory(\n",
    "            fold+'/test',\n",
    "            target_size=FIG_SHAPE,\n",
    "            batch_size= 10,\n",
    "            class_mode='binary')\n",
    "\n",
    "        #Get back the convolutional part of a VGG network trained on ImageNet\n",
    "        vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "        # Freeze the layers except the last 4 layers\n",
    "        for layer in vgg16_conv.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        #Create your own input format (here 3x200x200)\n",
    "        input = Input(shape=(FIG_SHAPE[0],FIG_SHAPE[1],3),name = 'image_input')\n",
    "\n",
    "        #Use the generated model \n",
    "        output_vgg16_conv = vgg16_conv(input)\n",
    "\n",
    "        #Add the fully-connected layers \n",
    "        x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "        x = Dense(4096, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        #Create your own model \n",
    "        my_model = Model(input=input, output=x)\n",
    "\n",
    "        #In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "        my_model.summary()\n",
    "\n",
    "        compile = my_model.compile(optimizer=optimizers.RMSprop(lr=1e-5), loss='binary_crossentropy',\n",
    "                               metrics=['accuracy'])\n",
    "\n",
    "        # Settting Callbacks\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3,verbose=1, cooldown=2)\n",
    "\n",
    "        callb_l = [reduce_lr]\n",
    "        # Train the model\n",
    "        my_model.fit_generator(\n",
    "              train_g,\n",
    "              steps_per_epoch=train_g.samples/train_g.batch_size ,\n",
    "              epochs=40,\n",
    "              validation_data=val_g,\n",
    "              validation_steps=val_g.samples/val_g.batch_size,\n",
    "              verbose=1,\n",
    "              callbacks=callb_l)\n",
    "        \n",
    "        my_model.evaluate_generator(generator=test_g,steps=1)\n",
    "        pred = my_model.predict_generator(test_g)\n",
    "\n",
    "        K.clear_session()\n",
    "        \n",
    "        pred[pred >= 0.5] = 1\n",
    "        pred[pred != 1 ] = 0\n",
    "        \n",
    "        k_labels.append(pred.ravel())\n",
    "    np.save('features_'+'fold_{}'.format(i),np.array(k_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "my_model = load_model(filepath='TL_OASIS_ax.h5')\n",
    "#print(my_model.summary())\n",
    "\n",
    "(eval_loss, eval_acc) = my_model.evaluate_generator(generator=test_g,steps=1)\n",
    "print('\\nEvaluation accuracy: {:.2f}'.format(eval_acc))\n",
    "\n",
    "pred = my_model.predict_generator(test_g)\n",
    "\n",
    "pred[pred >= 0.5] = 1\n",
    "pred[pred != 1 ] = 0\n",
    "\n",
    "print(classification_report(test_g.classes, pred.ravel()))\n",
    "print(np.reshape(pred,(1,len(pred))), test_g.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = my_model.predict_generator(train_g)\n",
    "pred_val   = my_model.predict_generator(val_g)\n",
    "pred_test = my_model.predict_generator(test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayTrain = np.vstack((pred_train,pred_val))\n",
    "trainY = np.hstack((train_g.classes,val_g.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('df_train_x.npy',arrayTrain)\n",
    "np.save('df_test_x.npy',pred_test)\n",
    "np.save('df_train_y.npy',trainY)\n",
    "np.save('df_test_y.npy',test_g.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "svc = SVC(C=100,gamma=2e-4)\n",
    "svc.fit(arrayTrain,trainY)\n",
    "pred_ar = svc.predict(pred_test)\n",
    "print(trainY)\n",
    "print(classification_report(pred_ar,test_g.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
